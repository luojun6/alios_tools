{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "# current_dir = os.path.dirname(__file__)\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "def get_file_by_suffix(suffix_name, dir_name=None, inclusive_keyword=None, exclusive_keyword=None):\n",
    "    if dir_name:\n",
    "        target_dir = os.path.abspath(os.path.join(current_dir, dir_name))\n",
    "    else:\n",
    "        target_dir = current_dir\n",
    "        \n",
    "    if type(suffix_name) is not str:\n",
    "        suffix_name = str(suffix_name)\n",
    "        \n",
    "    paths_hash = dict()\n",
    "    \n",
    "    if inclusive_keyword:\n",
    "        for path, sub_dirs, files in os.walk(target_dir):\n",
    "            for file in files:\n",
    "                if((file.endswith('.' + suffix_name) or \n",
    "                    file.endswith('.' + suffix_name.lower()) or \n",
    "                    file.endswith('.' + suffix_name.title()) or \n",
    "                    file.endswith('.' + suffix_name.upper()))) and (inclusive_keyword in file):\n",
    "                    paths_hash[file] = os.path.join(path, file)\n",
    "    \n",
    "    elif exclusive_keyword:\n",
    "        for path, sub_dirs, files in os.walk(target_dir):\n",
    "            for file in files:\n",
    "                if((file.endswith('.' + suffix_name) or \n",
    "                    file.endswith('.' + suffix_name.lower()) or \n",
    "                    file.endswith('.' + suffix_name.title()) or \n",
    "                    file.endswith('.' + suffix_name.upper()))) and (exclusive_keyword not in file):\n",
    "                    paths_hash[file] = os.path.join(path, file)\n",
    "                    \n",
    "    else:\n",
    "        for path, sub_dirs, files in os.walk(target_dir):\n",
    "            for file in files:\n",
    "                if(file.endswith('.' + suffix_name) or \n",
    "                    file.endswith('.' + suffix_name.lower()) or \n",
    "                    file.endswith('.' + suffix_name.title()) or \n",
    "                    file.endswith('.' + suffix_name.upper())):\n",
    "                    paths_hash[file] = os.path.join(path, file)\n",
    "                \n",
    "    return paths_hash\n",
    "\n",
    "log_type_col = \"log_type\"\n",
    "\n",
    "date = 'date'\n",
    "timestamp = 'timestamp'\n",
    "appid = 'appid'\n",
    "ctxid = 'ctxid'\n",
    "level = \"level\"\n",
    "payload = 'payload'\n",
    "payload_ext = \"payload_ext\"\n",
    "cols = [date, timestamp, appid, ctxid, level, payload, payload_ext]\n",
    "rename_cols = dict()\n",
    "for i in range(len(cols) - 1):\n",
    "    rename_cols[i] = cols[i]\n",
    "rename_cols\n",
    "\n",
    "def extract_gz_files(dir_name, log_type):\n",
    "    all_gz_dict = get_file_by_suffix(\"txt.gz\", dir_name=dir_name,  inclusive_keyword=log_type)\n",
    "    count = len(all_gz_dict)\n",
    "    i = 0\n",
    "    print(f\"Found {count} txt.gz files.\")\n",
    "    for key in all_gz_dict.keys():\n",
    "        i += 1\n",
    "        try:\n",
    "            print(f\"Extracting {key} with completion {i}/{count}.\")\n",
    "            log = pd.read_fwf(all_gz_dict[key], \n",
    "                                   compression=\"gzip\", \n",
    "                                   skiprows=3,\n",
    "                                   colspecs=\"infer\", \n",
    "                                   header=None,\n",
    "                                   encoding = \"ISO-8859-1\")\n",
    "            file_path = os.path.join(dir_name, key.replace(\"txt.gz\", \"csv\"))\n",
    "            log.rename(columns=rename_cols, inplace=True)\n",
    "#             log[log_type_col] = log_type\n",
    "            log.to_csv(file_path, encoding = \"ISO-8859-1\", index=None)\n",
    "        except pd.errors.EmptyDataError:\n",
    "                print(f\"Note: {key} was empty. Skipping.\")\n",
    "                continue # will skip the rest of the block and move to next file\n",
    "    print(\"Extraction completed.\")\n",
    "    \n",
    "def merge_log_csv_files(dir_name, inclusive_keyword=None):\n",
    "    all_csv_dict = get_file_by_suffix(\"csv\", dir_name=dir_name,  inclusive_keyword=inclusive_keyword)\n",
    "    all_log = pd.DataFrame()\n",
    "    count = len(all_csv_dict)\n",
    "    i = 0\n",
    "    print(f\"Found {count} txt.gz files.\")\n",
    "    \n",
    "    for key in all_csv_dict.keys():\n",
    "        i += 1\n",
    "        print(f\"Merging {key} with completion {i}/{count}.\")\n",
    "        temp_log = pd.read_csv(all_csv_dict[key], encoding = \"ISO-8859-1\", low_memory=False)\n",
    "        all_log = pd.concat([all_log, temp_log])\n",
    "    all_log.sort_values(by=[\"timestamp\"], inplace=True)\n",
    "    print(\"Merging compeleted.\")\n",
    "    \n",
    "    if inclusive_keyword is None:\n",
    "        inclusive_keyword = \"all_log\"\n",
    "    output_file_path = inclusive_keyword + \".csv\"\n",
    "    all_log.to_csv(output_file_path, encoding = \"ISO-8859-1\", index=None)\n",
    "    return all_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656deeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14968473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426bf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"emc/emc_sws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae77e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_gz_files(file_path, \"logcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0084132",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_gz_files(file_path, \"kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_gz_files(file_path, \"event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8e43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9581895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log = merge_log_csv_files(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29714300",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log[all_log[\"6\"].str.contains(\"monitor-monitor_data_frame_handler\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c27999",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_buffer_full = all_log[all_log[timestamp] < \"14:11:46.464\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_buffer_full.to_csv(\"before_buffer_full.csv\", encoding = \"ISO-8859-1\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25ca10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8a3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log = all_log.drop_duplicates(subset=[timestamp, payload, level]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031af77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log[((new_log[payload].str.lower().str.contains(\"power\")) \n",
    "        | (new_log[payload].str.lower().str.contains(\"kernel\"))\n",
    "        | (new_log[payload].str.lower().str.contains(\"ipk\")))\n",
    "        & ((new_log[timestamp] < \"10:30\") & (new_log[timestamp] > \"10:24\"))\n",
    "       ].to_csv(\"log_focus.csv\", encoding = \"ISO-8859-1\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1219f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log[((all_log[payload].str.contains(\"SRV\")) \n",
    "        | (all_log[payload].str.contains(\"kernel\"))\n",
    "        | (all_log[payload].str.contains(\"answer\")))\n",
    "        & (all_log[timestamp] < \"15:03:12\")\n",
    "       ].to_csv(\"log_focus.csv\", encoding = \"ISO-8859-1\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27422ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated = all_log.drop_duplicates(subset=[timestamp, payload]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c169aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log.to_csv(\"all_log.csv\", encoding = \"ISO-8859-1\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846b675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f35d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f49ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b775f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emc_error = pd.read_csv(\"emc_error.csv\", encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emc_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "emc_error[emc_error[date].isnull()].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ff911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
